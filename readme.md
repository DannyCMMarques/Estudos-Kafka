# Kafka Overview
## 1 - Kafka: Produtores, Consumidores e Streams

### O que Ã© o Kafka e quando usar

Kafka Ã© uma plataforma de **streaming distribuÃ­do** desenvolvida pela Apache, usada para processar grandes volumes de dados em tempo real. Ele Ã© ideal para sistemas que precisam lidar com eventos, logs, filas, integraÃ§Ã£o entre microsserviÃ§os e pipelines de dados.

**Use Kafka quando:**
- VocÃª precisa de **alta performance** e escalabilidade para mensagens/eventos.
- Os dados devem ser processados **em tempo real ou prÃ³ximo disso**.
- Ã‰ necessÃ¡rio **reter mensagens** por um tempo para reprocessamento.
- VÃ¡rios consumidores precisam acessar os **mesmos dados simultaneamente**.

---

### Alguns conceitos

- **Broker:** Servidor Kafka que recebe, armazena e entrega mensagens. Um cluster Kafka pode ter vÃ¡rios brokers distribuÃ­dos.

- **Producer:** Componente que publica mensagens em um tÃ³pico Kafka.

- **Consumer:** Componente que lÃª mensagens de um ou mais tÃ³picos Kafka.

- **Topic:** Canal lÃ³gico onde as mensagens sÃ£o publicadas. Cada tÃ³pico pode ter **vÃ¡rias partiÃ§Ãµes**.

  - **PartiÃ§Ãµes:** SubdivisÃµes do tÃ³pico que permitem paralelismo. Cada partiÃ§Ã£o mantÃ©m a **ordem das mensagens** e Ã© armazenada em disco.

---

### Ciclo de Mensagem

1. Um **producer** envia uma mensagem para um **broker**, publicando em um **tÃ³pico especÃ­fico**.
2. A mensagem Ã© armazenada em uma **partiÃ§Ã£o do tÃ³pico**.
3. Um ou mais **consumers** lÃªem as mensagens do tÃ³pico.
4. Cada consumer Ã© responsÃ¡vel por manter o **offset** (posiÃ§Ã£o) da Ãºltima mensagem consumida.
5. ApÃ³s o processamento bem-sucedido, o consumer pode fazer um **commit** do offset.
6. Se ocorrer falha, a mensagem pode ser redirecionada para uma **DLQ (Dead Letter Queue)**, se implementada.

---

### Plataforma de Streaming Kafka

- Armazena eventos com base em uma **retenÃ§Ã£o por tempo configurado**, e **nÃ£o por consumo**.
- Os eventos sÃ£o **imutÃ¡veis**: uma vez gravados, nÃ£o sÃ£o alterados.
- A responsabilidade de rastrear mensagens lidas Ã© do **consumer**.
- **Qualquer consumer** pode acessar uma mensagem, mesmo se jÃ¡ foi lida por outro.
- Kafka Ã© uma **plataforma de streaming distribuÃ­da**, escalÃ¡vel horizontalmente.

---

### Diagrama de Fluxo de Mensagem

```txt
           +------------+            +------------+           +-------------+
           |            |            |            |           |             |
           |  Producer  +----------->|   Broker   +----------->|  Consumer   |
           |            |  envia     |  (Topic)   |  entrega   | (leitor de  |
           +------------+  mensagens +------------+  mensagens |   eventos)  |
                                                         |     +-------------+
                                                         |
                                                   +-------------+
                                                   |   Consumer   |
                                                   |  (Analytics) |
                                                   +-------------+

         Mensagens ficam retidas por tempo (ex: 7 dias)
         Offset controlado pelos prÃ³prios consumidores
```

---

### Exemplo de uso comum

```txt
[Producer (Sistema A)] â†’ [Kafka (Topic: vendas)] â†’ [Consumer (Sistema B e Sistema C)]
```
- O Sistema A envia eventos de venda.
- O Sistema B processa e salva no banco.
- O Sistema C envia os eventos para um dashboard de BI.

---

### Produtores e Consumidores em Java

- **Produtores** sÃ£o implementados com `KafkaProducer` e enviam mensagens usando `ProducerRecord`.
- **Consumidores** usam `KafkaConsumer`, assinam tÃ³picos e fazem polling com `poll()`.
- O controle de **offsets** pode ser automÃ¡tico (auto-commit) ou manual.

---



### ğŸš¦ Paralelismo e CompetiÃ§Ã£o no Kafka

#### âš™ï¸ Paralelismo com PartiÃ§Ãµes

- Cada **partiÃ§Ã£o** pode ser processada por **apenas um consumidor dentro de um grupo**.
- Para obter paralelismo real, Ã© preciso:
  - Ter **mÃºltiplas partiÃ§Ãµes no tÃ³pico**.
  - Ter **mÃºltiplos consumidores no mesmo grupo**.

Exemplo:
```txt
TÃ³pico: pedidos (3 partiÃ§Ãµes)
Grupo: processamento-pedidos
Consumidores: C1, C2

Resultado:
- Kafka atribui 2 partiÃ§Ãµes para C1, 1 para C2
- Ambos processam mensagens em paralelo
```

#### âš”ï¸ CompetiÃ§Ã£o entre consumidores

- Em um mesmo grupo, os consumidores "competem" pelas partiÃ§Ãµes:
  - Cada partiÃ§Ã£o sÃ³ pode ser atribuÃ­da a **um Ãºnico consumidor** dentro do grupo.
  - Se um consumidor cair, Kafka redistribui as partiÃ§Ãµes (rebalanceamento).
- JÃ¡ **entre grupos diferentes**, nÃ£o hÃ¡ competiÃ§Ã£o:
  - Cada grupo recebe **todas** as mensagens.
  - Isso permite mÃºltiplas equipes/sistemas processarem os mesmos dados de formas diferentes.

---

### ğŸ’¡ ConclusÃ£o visual

```txt
             TÃ“PICO: PEDIDOS (3 partiÃ§Ãµes)
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚     Kafka     â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼            â–¼               â–¼             â–¼
     PartiÃ§Ã£o 0    PartiÃ§Ã£o 1     PartiÃ§Ã£o 2     [DLQ opcional]
        â”‚              â”‚               â”‚
    C1 (Grupo A)   C2 (Grupo A)   C3 (Grupo A)
        â”‚              â”‚               â”‚
       BI          Antifraude       LogÃ­stica

  â†’ Cada consumidor do Grupo A processa 1 partiÃ§Ã£o.
  â†’ Outro grupo (Grupo B) com outros consumidores pode receber TODAS as mensagens tambÃ©m.
```

Essa estrutura permite **escala horizontal**, **isolamento entre sistemas**, e **alto desempenho em tempo real**.

---

### Max Poll e Auto Commit

- `max.poll.records` define quantas mensagens o consumer pega por poll.
- `enable.auto.commit=false` permite controle manual, garantindo que apenas mensagens processadas com sucesso tenham seus offsets confirmados.

---

### Camadas Personalizadas

- Separar o cÃ³digo de Kafka em **camadas prÃ³prias** facilita manutenÃ§Ã£o:
  - `KafkaProducerService`: centraliza o envio de eventos.
  - `KafkaConsumerHandler`: processa mensagens recebidas.
- Isso melhora a organizaÃ§Ã£o e facilita testes unitÃ¡rios.

---

### SerializaÃ§Ã£o e DesserializaÃ§Ã£o Customizada

- Kafka usa **serializadores** e **desserializadores** para transformar objetos em bytes.
- Podemos criar **Serializers/Deserializers personalizados** com bibliotecas como **GSON** ou **Jackson** para JSON.

```java
public class PedidoSerializer implements Serializer<Pedido> {
    @Override
    public byte[] serialize(String topic, Pedido data) {
        return new Gson().toJson(data).getBytes();
    }
}
```

---

### DLQ (Dead Letter Queue)

- Mensagens que falham no processamento podem ser redirecionadas para uma fila de erro.
- Evita perda de dados e permite correÃ§Ã£o posterior.

---

### MicrosserviÃ§os com Kafka

- Kafka facilita integraÃ§Ã£o entre microsserviÃ§os.
- Cada serviÃ§o pode ser produtor ou consumidor.
- MicrosserviÃ§os ficam **desacoplados** e mais fÃ¡ceis de escalar.

---

### Monorepo e Bibliotecas Comuns

- Em um monorepo, podemos criar **mÃ³dulos compartilhados**:
  - Ex: `commons-kafka`, `commons-logger`
- Reutiliza cÃ³digo e padroniza uso do Kafka entre os serviÃ§os.

---

### Rebalance

### ConclusÃ£o

- Kafka Ã© uma soluÃ§Ã£o robusta para mensageria em tempo real.
- Aprendemos a criar produtores e consumidores em Java.
- Estudamos paralelismo, offset, auto-commit e partilhas.
- Implementamos camadas organizadas e serializaÃ§Ãµes customizadas.
- Vimos boas prÃ¡ticas com DLQ, microsserviÃ§os e monorepo.

Kafka nÃ£o Ã© apenas uma fila: Ã© uma plataforma de eventos para arquiteturas modernas.

## 2Â â€“Â Kafka: Fast Delegate, EvoluÃ§Ã£oÂ eÂ ClusterÂ deÂ Brokers

A seÃ§Ã£o a seguir aprofunda os conceitos apresentados na trilha **â€œFastâ€¯Delegate, evoluÃ§Ã£o e cluster de brokersâ€** e mostra como aplicÃ¡â€‘los em um projeto **SpringÂ BootÂ +Â Springâ€¯forâ€¯ApacheÂ Kafka**.

| #  | TÃ³pico do curso | Conceito na teoria | TraduÃ§Ã£o prÃ¡tica no Spring |
|----|-----------------|--------------------|---------------------------|
| **2.1Â â€¢Â SingleÂ PointÂ ofÂ Failure doÂ Broker** | Um cluster com **apenas 1 broker** cai â‡’ toda a plataforma fica fora do ar. | âš™ï¸Â Crie **â‰¥â€¯2 brokers** e use `replication.factorÂ >Â 1`. No Spring basta listar todos em `spring.kafka.bootstrap-servers`; o client faz failâ€‘over automÃ¡tico. |
| **2.2Â â€¢Â ReplicaÃ§Ã£o emÂ Cluster** | Cada partiÃ§Ã£o tem **1 lÃ­der** e algumas **rÃ©plicas** (followers). Se o lÃ­der falhar, um follower assume. | No broker: `default.replication.factor=3`, `min.insync.replicas=2`. O driver Spring lÃª a _metadata_ e continua produzindo/consumindo. |
| **2.3Â â€¢Â ClusterÂ deÂ 5Â Brokers, LÃ­deresÂ &Â RÃ©plicas** | Exemplo real com 5 nÃ³s; 3 rÃ©plicas/partiÃ§Ã£o, 2 followers sempre *inâ€‘sync*. | No `docker-compose` adicione `kafka1â€¦kafka5`. A app Spring aponta para qualquer broker da lista (`kafka1:9092,â€¦`); o client descobre o resto. |
| **2.4Â â€¢Â AcksÂ &Â Reliability** | ConfirmaÃ§Ã£o de escrita (`acks=0 | 1 | all`), idempotÃªncia, retries, timeouts. | Em `application.yml`:<br>`acks=all`, `enable-idempotence=true`, `retries=3`, `delivery.timeout.ms=30000`. |

---

### 2.1Â â€¢Â SingleÂ PointÂ ofÂ FailureÂ (SPOF)Â doÂ Broker

| | DescriÃ§Ã£o |
|---|---|
| **DefiniÃ§Ã£o** | Se houver sÃ³ **um** broker e ele falhar, producers e consumers ficam sem destino. |
| **Sintomas** | Logs: `NOT_LEADER_NOT_AVAILABLE`, latÃªncia 100â€¯%, throughput 0. |
| **CorreÃ§Ã£o** | Adicionar brokers e setar `replication.factorÂ >Â 1`; definir `min.insync.replicas` para consistÃªncia. |
| **No Spring** | MÃºltiplos hosts em `bootstrap-servers`. O client troca de lÃ­der sozinho.|

---

### 2.2Â â€¢Â ReplicaÃ§Ã£o emÂ Cluster (LÃ­derÂ &Â Followers)

* **LÃ­der** grava todas as mensagens e responde ao producer.  
* **Followers** replicam o log do lÃ­der.  
* **ISR (inâ€‘sync replicas)** = subconjunto de rÃ©plicas totalmente atualizadas.  
* Se o lÃ­der cair â†’ o controller elege outro nÃ³ do ISR como novo lÃ­der em milissegundos.

```properties
# No broker
default.replication.factor=3
min.insync.replicas=2
```

---

### 2.3Â â€¢Â ClusterÂ deÂ 5Â Brokers

DistribuiÃ§Ã£o (RFÂ =Â 3):

| PartiÃ§Ã£o | LÃ­der | FollowerÂ 1 | FollowerÂ 2 |
|----------|-------|------------|------------|
| 0 | **B1** | B3 | B5 |
| 1 | **B2** | B4 | B1 |
| 2 | **B3** | B5 | B2 |
| â€¦ | â€¦ | â€¦ | â€¦ |

*Mais nÃ³sÂ â‡’ mais throughput e tolerÃ¢ncia a falhas (rack awareness).*

---

### 2.4Â â€¢Â AcksÂ &Â Reliability

| `acks` | Quem confirma | SemÃ¢ntica | Quando usar |
|--------|--------------|-----------|-------------|
| **0** | NinguÃ©m | _Atâ€‘mostâ€‘once_ | Telemetria nÃ£o crÃ­tica |
| **1** | LÃ­der | _Atâ€‘leastâ€‘once_ (pode perder se o lÃ­der falhar antes do sync) | Default Kafka |
| **all / -1** | LÃ­derÂ + ISR | _Atâ€‘leastâ€‘once_ + alta durabilidade; com idempotÃªncia chega a _exactlyâ€‘once_ | Dados financeiros |

#### ConfiguraÃ§Ã£o recomendada

```yaml
spring:
  kafka:
    producer:
      acks: all
      enable-idempotence: true
      retries: 3
      properties:
        delivery.timeout.ms: 30000
```

---

### FastÂ Delegation (Failâ€‘over rÃ¡pido)

* Nome informal do curso para o **algoritmo de eleiÃ§Ã£o de lÃ­der** + atualizaÃ§Ã£o instantÃ¢nea de _metadata_.
* O client Spring se mantÃ©m conectado via heartbeats; ao receber nova tabela de partiÃ§Ãµes, retoma o envio ou consumo sem intervenÃ§Ã£o manual.

---

### EvoluÃ§Ã£o de Cluster

1. **Escalar**: adicionar brokers, alterar partiÃ§Ãµes (`kafka-topics --alter`) e reâ€‘balancear (`kafka-reassign-partitions`).  
2. **Upgrade**: _rolling update_ (um broker por vez) ajustando `inter.broker.protocol.version`.  
3. **Armazenamento**: habilitar Tiered Storage ou compactaÃ§Ã£o por nÃ­vel.

#### MÃ©tricas a observar

* `under-replicated-partitions`  
* `offline-partitions-count`  
* `controller.election-rate`  
* `request-latency-avg`

---

### application-docker.yml â€“ exemplo completo

```yaml
spring:
  kafka:
    bootstrap-servers: kafka1:9092,kafka2:9092,kafka3:9092,kafka4:9092,kafka5:9092
    producer:
      acks: all
      retries: 3
      enable-idempotence: true
      key-serializer: org.apache.kafka.common.serialization.IntegerSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      properties:
        delivery.timeout.ms: 30000
    admin:
      properties:
        bootstrap.servers: ${spring.kafka.bootstrap-servers}
```

> ğŸ’¡ **Dica**Â â€“ use um perfil `local` com `bootstrap-servers: localhost:9092` para desenvolvimento singleâ€‘node, e `docker`/`prod` para cluster.

---

### Teste de Failâ€‘over

1. Com o cluster rodando, execute: `docker compose stop kafka1`.  
2. Observe logs no Spring: breves `WARN â€¦ node â€‘1 disconnected`, depois normaliza.  
3. Mensagens continuam fluindo; com `acks=all` & `min.insync.replicasâ‰¥2` nÃ£o hÃ¡ perda.

---

**ConclusÃ£o**: aplicando as prÃ¡ticas acima â€” mÃºltiplos brokers, replicaÃ§Ã£o adequada, `acks=all` + idempotÃªncia â€” seu sistema Kafka tornaâ€‘se resiliente, escalÃ¡vel e pronto para produÃ§Ã£o empresarial.
